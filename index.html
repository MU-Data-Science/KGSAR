<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <title>KGSAR-Keyboard</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" type="text/css" href="css/index-style.css"/>
</head>
<body>
    <nav class="navbar navbar-expand-lg navbar-light">
        <div class="collapse navbar-collapse" id="navbarNavAltMarkup">
          <div class="navbar-nav">
            <a class="nav-item nav-link active" href="https://www.umkc.edu/mide/NEH-Project/">KGSAR</a>
            <a class="nav-item nav-link" href="#">Demo</a>
            <a class="nav-item nav-link" href="keyboard.html">Keyboard</a>
            <a class="nav-item nav-link" href="https://github.com/MU-Data-Science/KGSAR">GitHub</a>
          </div>
        </div>
    </nav>

    <div class="h3-div-specs">
        <h3>KGSAR: A Knowledge Graph-Based Tool for Managing Spanish Colonial Notary Records</h3>
    </div>

    <div class="card">
        <div class="card-horizontal"> 
            <div class="card-body">
                <h4 class="card-title">INTRODUCTION & MOTIVATION</h4>
                <p class="card-text">
                    Notary records contain abundant information relevant to historical inquiry but are in physical form and hence, searching for information in these documents could be painstaking. We present a novel document retrieval system that allows users to search for a keyword in digitized copies of physical records. </br>
                    The system uses cleaned and denoised images to search a keyword using optical character recognition (OCR) models re-trained on labeled data provided by experts. The word predictions, bounding boxes, and other information are stored as a knowledge graph (KG). </br>
                    A keyword query is then mapped to a graph query on the KG. The results are ranked based on text matching. An intuitive user interface (UI) allows a user to search, correct, delete or draw more annotations that  are used for retraining of the OCR models.
                </p>
            </div>
        </div>
    </div>

    <div class="card text-center">
        <div class="card-body">
            <h4 class="card-title">SYSTEM ARCHITECTURE</h4>
            <!-- <video id="video_background" controls="controls" preload="auto" width="600" height="400" autoplay loop muted>
                <source src="docs/static/System-Architecture-2.mov">
            </video> -->

            <iframe id="video" width="600" height="400" src="ocs/static/System-Architecture-2.mov" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>
        </div>
    </div>

    <div class="card">
        <div class="card-horizontal"> 
            <div class="card-body" id="first">
                <h4 class="card-title">DATASET</h4>
                <p class="card-text">
                    <ul class="ul-props">
                        <li>Seventeenth-century manuscripts available at Archivo General de la República Argentina, Buenos Aires.</li>
                        <li>220,000 pages of digital images.</li>
                        <li>Multiple handwritings</li>
                        <ul>
                            <li>Selected: Nicolas de Valdibia y Brizuela, interim notary by 1650.</li>
                        </ul>
                    </ul>
                    <p style="padding-left:20px;">On the right, we have shown examples of 3 different handwritings. For our experiments, we selected the hand of Nicolas de Valdibia y Brizuela who by 1650, acted as the interim notary. Interim notaries did not receive extensive training, nor were they skilled scribes. The dataset thus consisted of very irregular and hard-to-read scripts. </p>
                </p>
            </div>
            <div class="img-square-wrapper" id="second">
                <p style="text-align:right"><img src="docs/static/dataset.png" width="400px;" height="250px;"></p>
            </div> 
        </div>
    </div>
    
    <div class="card text-right">
        <div class="card-body">
            <h4 class="card-title">IMAGE PROCESSING & DATASET CREATION</h4>
            <p class="card-text">
                <div class="img-square-wrapper" id="third">
                    <p><img src="docs/static/image-preprocessing.png" width="600px;"></p>
                </div>
                <div id="fourth">
                    <p>Component A or Image Preprocessing was our first step. Scans contain different types of noise including discoloration, stains, ink bleeds and smudges. Throughout this preprocessing, techniques have been applied to clean the images without affecting the written content. This allowed us to retain information in the images without having abundance of redundant information.</p>
                    <p><b>GRAYSCALE:</b> Convert original scans of images into shades of gray so more complex operations can be performed in shorter time
                    </p>
                    <p><b>MEDIAN FILTER:</b> To soften the images’ background & remove background noise
                    </p>
                    <p><b>IMAGE BINARIZATON:</b> Convert grayscale images to black and white to reduce information contained in images and increase training speed
                    </p>
                    <p><b>WORDS DATASET (Component B): </b> <a href="https://github.com/tzutalin/labelImg">LabelImg</a> and <a href="http://www.colabeler.com">Colabeler</a> to annotate and label words in each image. Images were then cropped using the bounding boxes and labels. We padded these to maintain similar dimensions. Finally, <b>83 images (166 manuscript pages), 26,482 words (6,401 unique)</b> were generated.
                    </p>
                </div> 
            </p>
        </div>
    </div>

    <div class="card">
        <div class="card-body">
          <h4 class="card-title text-center">MODELS</h4>
          <p class="card-text"> Model Training was our next step, Component C. Out of the numerous ML OCR models available, Keras-OCR and YOLO-OCR yielded the most promising results. While experimenting, we tested with YOLOv2, YOLOv3, Calamari, Kraken & Tesseract [1]. The first two models performed unsatisfactorily where those bounding boxes that were detected were unlabeled. Calamari, Kraken & Tesseract were able to detect lines but were unable to detect the words within those lines. This is because they were trained on printed text. Moreover, we wanted to use word detections to build our system [2]. During training, the train to test split was  90 to 10 for both the OCRs.</p>
          <div class="row">
            <div class="col-sm-6">
              <div class="card">
                <div class="card-body">
                    <h5 class="card-title text-center">KERAS-OCR</h5>
                    <p class="card-text">We trained the recognizer using CRNN (kurupan) on our words dataset. We used the default detector, CRAFT (clovaai_general) as it was able to detect maximum of the words in a given image. Patches from 77 images were used. We observed that although most of the words were detected, the quality of recognition could be improved with further retraining.</p>

                    <div style="text-align: center;">
                        <img src="docs/static/keras-detection.jpg">
                    </div>
                </div>
              </div>
            </div>
            <div class="col-sm-6">
              <div class="card">
                <div class="card-body">
                    <h5 class="card-title text-center">YOLO-OCR</h5>
                    <p class="card-text">The prediction was performed in four steps. Firstly, we passed a test image to the trained YOLO-OCR model to localize all the possible words’ coordinates and write them to a text file. Then, we cropped all the detected words and saved them as .png images. Thirdly, we resized the generated patches to match the input size of the CRNN model. Finally, we passed the .png images to the CRNN model to recognize the word.</p>

                    <div style="text-align: center;">
                        <img src="docs/static/yolo-detection.jpg">
                    </div>
                </div>
              </div>
            </div>
          </div>
            <p class="card-text">
                The above two images show detection in Keras-OCR vs YOLO-OCR. Although fewer words were detected with respect to Keras-OCR, the quality of recognition was much better in YOLO-OCR. 
            </p>
            <p class="card-text" style="font-size: 12px;">
                [1] Alrasheed, N., Prasanna, S., Rowland, R., Rao, P., Grieco, V. and Wasserman, M., October. Evaluation of Deep Learning Techniques for Content Extraction in Spanish Colonial Notary Records. In Proceedings of the 3rd Workshop on Structuring and Understanding of Multimedia heritAge Contents, 23-30 (2021). <br>
                [2] Alrasheed, N., Rao, P. and Grieco, V., Character Recognition Of Seventeenth-Century Spanish American Notary Records Using Deep Learning. Digital Humanities Quarterly 15(4) (2021).
            </p>
        </div>
    </div>
      
    <div class="card text-left">
        <div class="card-body">
            <h4 class="card-title">KNOWLEDGE GRAPHS</h4>
            <div id="fifth">
                <p class="card-text"> Component D focusses in structuring all the acquired data into directed graphs, that is, knowledge graphs (KG). We utilize knowledge graphs to address the challenges in accessing, reading, and searching within the documents. We serialized the information into turtle (.ttl) format. For the graph storage, we utilize an open-source, ultra-high performance graph database called <a href="https://blazegraph.com">Blazegraph</a> (Component E). We used Resource Description Framework (RDF) standards and SPARQL queries for insertion and querying.</p>

                <p class="card-text"> Knowledge: Predicted words, the bounding box coordinates for each prediction, the model type that predicted and the path of the images, that is which page or which document or ‘Rollo’.
                </p>

                <p class="card-text"> Blazegraph provides multiple features, and we employed two of them in our tool: 
                    <ul>
                        <li>Bulk Data Loader: 
                            <ul>
                                <li>Utility to create or load RDF data into local data instance.</li>
                                <li>Average speed of upload for 5 turtles: just a few minutes!</li>
                            </ul>
                        </li>
                        <li>FullTextSearch: 
                            <ul>
                                <li>Provides fast, scalable full text search and retrieval.</li>
                                <li>Indexing can do REGEX, prefix, exact and partial matches.</li>
                                <li>Allows the results to be ranked in the order of relevance, that is, based on the score.</li>
                            </ul>
                        </li>
                    </ul> 
                </p>
            </div>
            <div id="second">
                <p style="text-align:right"><img src="docs/static/Ontology.png" width="550px;" height="400px;"></p>
            </div>
        </div>
    </div>

    <div class="card text-center">
        <div class="card-body">
            <h4 class="card-title">KGSAR AS AN IR TOOL</h4>
            <p class="card-text">Main features of our tool:
                <ul style="list-style-type: '\2713';">
                    <li style="padding-left: 10px;">Search for a word</li>
                    <li style="padding-left: 10px;">Correct a result</li>
                    <li style="padding-left: 10px;">Annotate/label more words in the results</li>
                    <li style="padding-left: 10px;">Delete an incorrect result</li>
                    <li style="padding-left: 10px;">Available as a <a href="https://github.com/MU-Data-Science/KGSAR/blob/main/Search-Engine/README.md#accessing-using-docker">Docker image</a></li>
                </ul>
            </p>
        </div>
        <div class="row">
            <div class="col-sm-6">
              <div class="card">
                <div class="card-body">
                    <h5 class="card-title">SEARCH</h5>
                    <p class="card-text">
                        <ul>
                            <b>QUERY</b> </br> Search for any word from 20,000 images of pages from documents containing 3 different handwritings.
                        </ul>
                        <ul>
                            <b>NUMBER OF RESULTS</b> </br> Choose from top 5, 10, 15, 20 or all the results.
                        </ul>
                        <ul>
                            <b>QUERY TIME</b> </br> View results within a few seconds of searching (lazy loading).
                        </ul>
                        <ul>
                            <b>RESEARCH</b> </br> Minimalist and easy to use for historians and other users.
                        </ul>
                    </p>
                    <div style="text-align: center;">
                        <video id="video_background" preload="auto" width="600" height="400" autoplay loop muted>
                            <source src="docs/static/search.mov">
                        </video>
                    </div>
                </div>
              </div>
            </div>
            <div class="col-sm-6">
              <div class="card">
                <div class="card-body">
                    <h5 class="card-title">ANNOTATION</h5>
                    <p class="card-text">
                        <ul>
                            <b>UPDATE</b> </br> Correct a prediction by editing a label.
                        </ul>
                        <ul>
                           <b>ANNOTATE</b> </br> Provide more annotates by freely drawing bounding boxes to label.
                        </ul>
                        <ul>
                            <b>DELETE</b> </br> Incorrect result? Delete the prediction!
                        </ul>
                        <ul>
                            <b>SAVE</b> </br> All the above features allow the user to email the actions to us. Additional annotations are used for further retraining and deleted annotations will be removed from search results​.
                        </ul>
                    </p>
                    <div style="text-align: center;">
                        <video id="video_background" preload="auto" width="600" height="400" autoplay loop muted>
                            <source src="docs/static/annotate.mov">
                        </video>
                    </div>
                </div>
              </div>
            </div>
          </div>
    </div>


    <div id="footer">
        <div id="grantLang-div" class="grantLang">
            This work was supported by the National Endowment for the Humanities under Grant No. <a href="https://securegrants.neh.gov/publicquery/main.aspx?f=1&gn=HAA-271747-20" target="_blank">HAA-271747-20</a>.
          </div>
      
          <div id="img-div">
            <div class="imageColumn">
              <img id="img-id" src='logos/NEH-Preferred-Seal820.jpg' alt="NEH" title="National Endowment For The Humanities">
            </div>
            <div class="imageColumn">
              <img id="img-id" src='logos/UMKC.jpg' alt="UMKC" title="University of Missouri - Kansas City">
            </div>
            <div class="imageColumn">
              <img id="img-id" src='logos/UM.png' alt="Mizzou" title="University of Missouri - Columbia">
            </div>
            <div class="imageColumn">
              <img id="img-id" src='logos/Logo-Ravignani-2020.jpg' alt="Instituto De Historia Argentina Y Americana" title = "Instituto De Historia Argentina Y Americana - Dr. Emilio Ravignani">
            </div>
          </div>
          <div id="img-div2">
            <div class="imageColumn2">
              <img id="img-id2" src='logos/Archivo General  de la Nacion-BW.jpg' alt="Archivo General  de la Nacion" title = "Archivo General  de la Nacion">
            </div>
          </div>
        </div>

    <script type="text/javascript">
        
    </script>
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
</body>
</html>